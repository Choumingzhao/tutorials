
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/basics/saveloadrun_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_basics_saveloadrun_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_basics_saveloadrun_tutorial.py:


`Learn the Basics <intro.html>`_ ||
`Quickstart <quickstart_tutorial.html>`_ ||
`Tensors <tensorqs_tutorial.html>`_ ||
`Datasets & DataLoaders <data_tutorial.html>`_ ||
`Transforms <transforms_tutorial.html>`_ ||
`Build Model <buildmodel_tutorial.html>`_ ||
`Autograd <autogradqs_tutorial.html>`_ ||
`Optimization <optimization_tutorial.html>`_ ||
**Save & Load Model**

Save and Load the Model
============================

In this section we will look at how to persist model state with saving, loading and running model predictions.

.. GENERATED FROM PYTHON SOURCE LINES 17-22

.. code-block:: default


    import torch
    import torchvision.models as models









.. GENERATED FROM PYTHON SOURCE LINES 23-28

Saving and Loading Model Weights
--------------------------------
PyTorch models store the learned parameters in an internal
state dictionary, called ``state_dict``. These can be persisted via the ``torch.save``
method:

.. GENERATED FROM PYTHON SOURCE LINES 28-32

.. code-block:: default


    model = models.vgg16(weights='IMAGENET1K_V1')
    torch.save(model.state_dict(), 'model_weights.pth')





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://download.pytorch.org/models/vgg16-397923af.pth" to /var/lib/jenkins/.cache/torch/hub/checkpoints/vgg16-397923af.pth

      0%|          | 0.00/528M [00:00<?, ?B/s]
      1%|1         | 5.62M/528M [00:00<00:09, 58.3MB/s]
      2%|2         | 12.4M/528M [00:00<00:08, 66.0MB/s]
      4%|3         | 18.7M/528M [00:00<00:08, 61.6MB/s]
      5%|4         | 24.7M/528M [00:00<00:08, 60.3MB/s]
      6%|6         | 32.8M/528M [00:00<00:07, 69.0MB/s]
      8%|7         | 40.8M/528M [00:00<00:06, 73.6MB/s]
      9%|9         | 48.2M/528M [00:00<00:06, 75.0MB/s]
     11%|#         | 56.0M/528M [00:00<00:06, 76.8MB/s]
     12%|#2        | 63.4M/528M [00:00<00:06, 71.5MB/s]
     13%|#3        | 70.3M/528M [00:01<00:06, 71.4MB/s]
     15%|#4        | 77.1M/528M [00:01<00:07, 65.5MB/s]
     16%|#6        | 85.3M/528M [00:01<00:06, 70.9MB/s]
     18%|#7        | 92.4M/528M [00:01<00:06, 72.1MB/s]
     19%|#8        | 99.6M/528M [00:01<00:06, 72.9MB/s]
     20%|##        | 107M/528M [00:01<00:06, 73.0MB/s] 
     22%|##1       | 114M/528M [00:01<00:05, 75.6MB/s]
     23%|##3       | 122M/528M [00:01<00:06, 70.4MB/s]
     24%|##4       | 128M/528M [00:01<00:06, 68.7MB/s]
     26%|##5       | 136M/528M [00:02<00:05, 71.1MB/s]
     27%|##7       | 143M/528M [00:02<00:06, 65.7MB/s]
     28%|##8       | 149M/528M [00:02<00:06, 61.8MB/s]
     30%|##9       | 157M/528M [00:02<00:05, 66.9MB/s]
     31%|###1      | 164M/528M [00:02<00:05, 68.9MB/s]
     32%|###2      | 171M/528M [00:02<00:05, 71.6MB/s]
     34%|###3      | 178M/528M [00:02<00:05, 72.1MB/s]
     35%|###5      | 185M/528M [00:02<00:05, 66.1MB/s]
     37%|###6      | 193M/528M [00:02<00:05, 70.0MB/s]
     38%|###7      | 200M/528M [00:03<00:05, 63.5MB/s]
     39%|###9      | 206M/528M [00:03<00:05, 63.7MB/s]
     40%|####      | 212M/528M [00:03<00:05, 64.2MB/s]
     41%|####1     | 219M/528M [00:03<00:05, 61.4MB/s]
     43%|####2     | 226M/528M [00:03<00:04, 65.4MB/s]
     44%|####4     | 232M/528M [00:03<00:04, 63.4MB/s]
     45%|####5     | 239M/528M [00:03<00:04, 65.2MB/s]
     46%|####6     | 245M/528M [00:03<00:05, 59.0MB/s]
     48%|####7     | 252M/528M [00:03<00:04, 61.2MB/s]
     49%|####8     | 258M/528M [00:04<00:04, 62.8MB/s]
     50%|#####     | 265M/528M [00:04<00:04, 64.3MB/s]
     51%|#####1    | 271M/528M [00:04<00:04, 63.4MB/s]
     53%|#####2    | 278M/528M [00:04<00:03, 67.5MB/s]
     54%|#####3    | 285M/528M [00:04<00:03, 65.9MB/s]
     55%|#####5    | 292M/528M [00:04<00:03, 69.4MB/s]
     57%|#####6    | 299M/528M [00:04<00:03, 65.3MB/s]
     58%|#####7    | 306M/528M [00:04<00:03, 67.9MB/s]
     59%|#####9    | 313M/528M [00:04<00:03, 69.0MB/s]
     61%|######    | 321M/528M [00:04<00:02, 72.6MB/s]
     62%|######2   | 328M/528M [00:05<00:02, 72.6MB/s]
     63%|######3   | 335M/528M [00:05<00:02, 74.4MB/s]
     65%|######4   | 342M/528M [00:05<00:02, 74.2MB/s]
     66%|######6   | 349M/528M [00:05<00:02, 65.7MB/s]
     67%|######7   | 356M/528M [00:05<00:02, 64.5MB/s]
     69%|######8   | 363M/528M [00:05<00:02, 66.4MB/s]
     70%|#######   | 370M/528M [00:05<00:02, 68.7MB/s]
     72%|#######1  | 378M/528M [00:05<00:02, 73.1MB/s]
     73%|#######2  | 385M/528M [00:05<00:01, 74.8MB/s]
     74%|#######4  | 392M/528M [00:06<00:01, 72.6MB/s]
     76%|#######5  | 400M/528M [00:06<00:01, 73.9MB/s]
     77%|#######7  | 407M/528M [00:06<00:01, 69.8MB/s]
     78%|#######8  | 414M/528M [00:06<00:01, 67.4MB/s]
     80%|#######9  | 421M/528M [00:06<00:01, 70.6MB/s]
     81%|########1 | 428M/528M [00:06<00:01, 66.5MB/s]
     82%|########2 | 434M/528M [00:06<00:01, 64.9MB/s]
     84%|########3 | 441M/528M [00:06<00:01, 67.3MB/s]
     85%|########4 | 449M/528M [00:06<00:01, 69.3MB/s]
     86%|########6 | 455M/528M [00:07<00:01, 67.6MB/s]
     88%|########7 | 463M/528M [00:07<00:00, 71.9MB/s]
     89%|########9 | 471M/528M [00:07<00:00, 74.7MB/s]
     91%|######### | 478M/528M [00:07<00:00, 75.9MB/s]
     92%|#########2| 486M/528M [00:07<00:00, 71.1MB/s]
     93%|#########3| 493M/528M [00:07<00:00, 64.4MB/s]
     95%|#########4| 499M/528M [00:07<00:00, 61.8MB/s]
     96%|#########5| 506M/528M [00:07<00:00, 65.2MB/s]
     97%|#########7| 513M/528M [00:07<00:00, 67.5MB/s]
     98%|#########8| 520M/528M [00:07<00:00, 67.9MB/s]
    100%|#########9| 527M/528M [00:08<00:00, 70.0MB/s]
    100%|##########| 528M/528M [00:08<00:00, 68.3MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 33-35

To load model weights, you need to create an instance of the same model first, and then load the parameters
using ``load_state_dict()`` method.

.. GENERATED FROM PYTHON SOURCE LINES 35-40

.. code-block:: default


    model = models.vgg16() # we do not specify weights, i.e. create untrained model
    model.load_state_dict(torch.load('model_weights.pth'))
    model.eval()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    VGG(
      (features): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace=True)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace=True)
        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (6): ReLU(inplace=True)
        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (8): ReLU(inplace=True)
        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (11): ReLU(inplace=True)
        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (13): ReLU(inplace=True)
        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (15): ReLU(inplace=True)
        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (18): ReLU(inplace=True)
        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (20): ReLU(inplace=True)
        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (22): ReLU(inplace=True)
        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (25): ReLU(inplace=True)
        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (27): ReLU(inplace=True)
        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (29): ReLU(inplace=True)
        (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
      (classifier): Sequential(
        (0): Linear(in_features=25088, out_features=4096, bias=True)
        (1): ReLU(inplace=True)
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=4096, out_features=4096, bias=True)
        (4): ReLU(inplace=True)
        (5): Dropout(p=0.5, inplace=False)
        (6): Linear(in_features=4096, out_features=1000, bias=True)
      )
    )



.. GENERATED FROM PYTHON SOURCE LINES 41-42

.. note:: be sure to call ``model.eval()`` method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results.

.. GENERATED FROM PYTHON SOURCE LINES 44-49

Saving and Loading Models with Shapes
-------------------------------------
When loading model weights, we needed to instantiate the model class first, because the class
defines the structure of a network. We might want to save the structure of this class together with
the model, in which case we can pass ``model`` (and not ``model.state_dict()``) to the saving function:

.. GENERATED FROM PYTHON SOURCE LINES 49-52

.. code-block:: default


    torch.save(model, 'model.pth')








.. GENERATED FROM PYTHON SOURCE LINES 53-54

We can then load the model like this:

.. GENERATED FROM PYTHON SOURCE LINES 54-57

.. code-block:: default


    model = torch.load('model.pth')








.. GENERATED FROM PYTHON SOURCE LINES 58-59

.. note:: This approach uses Python `pickle <https://docs.python.org/3/library/pickle.html>`_ module when serializing the model, thus it relies on the actual class definition to be available when loading the model.

.. GENERATED FROM PYTHON SOURCE LINES 61-64

Related Tutorials
-----------------
`Saving and Loading a General Checkpoint in PyTorch <https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html>`_


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  13.748 seconds)


.. _sphx_glr_download_beginner_basics_saveloadrun_tutorial.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: saveloadrun_tutorial.py <saveloadrun_tutorial.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: saveloadrun_tutorial.ipynb <saveloadrun_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
